{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i-saksham sentiment analysis.ipynb",
      "provenance": [],
      "mount_file_id": "19cNZlrPD68Zuno32Dp9V7aypp6xARrRv",
      "authorship_tag": "ABX9TyNhqTrb2OLRkXz/NIl4VZIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Addityaverma/LENDING-CLUBS/blob/master/i_saksham_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Zr4QxOFtN3G0",
        "outputId": "b7f4d580-2f6f-4d38-9509-d7e6a14db57f"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[86]:\n",
        "\n",
        "\n",
        "import re\n",
        "import regex\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from spacy.lang.hi import STOP_WORDS as STOP_WORDS_HI\n",
        "import IPython\n",
        "import kaleido\n",
        "from tkinter import *\n",
        "from tkinter import Label\n",
        "from tkinter import Button\n",
        "from tkinter import Checkbutton\n",
        "from tkinter import Tk\n",
        "from tkinter import filedialog\n",
        "import sys\n",
        "import os\n",
        "import tkinter\n",
        "from tkinter.constants import *\n",
        "import PySimpleGUI as sg\n",
        "\n",
        "\n",
        "# In[91]:\n",
        "\n",
        "\n",
        "def do(filepath,folderpath,list_users):\n",
        "    \n",
        "    sg.popup_notify(\"Wait for Analysis\")\n",
        "    \n",
        "    path = folderpath\n",
        "    \n",
        "    def date_time(s):\n",
        "        pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "        result = regex.match(pattern, s)\n",
        "        if result:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def find_author(s):\n",
        "        s = s.split(\":\")\n",
        "        if len(s)==2:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def getDatapoint(line):\n",
        "        splitline = line.split(' - ')\n",
        "        dateTime = splitline[0]\n",
        "        date, time = dateTime.split(\",\")\n",
        "        message = \" \".join(splitline[1:])\n",
        "        if find_author(message):\n",
        "            splitmessage = message.split(\": \")\n",
        "            author = splitmessage[0]\n",
        "            message = \" \".join(splitmessage[1:])\n",
        "        else:\n",
        "            author= None\n",
        "        return date, time, author, message\n",
        "    \n",
        "    data = []\n",
        "    #conversation = 'WhatsApp Chat with Jeevika-i-Saksham fellows.txt'\n",
        "    conversation = filepath\n",
        "    with open(conversation, encoding=\"utf-8\") as fp:\n",
        "        fp.readline()\n",
        "        messageBuffer = []\n",
        "        date, time, author = None, None, None\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if date_time(line):\n",
        "                if len(messageBuffer) > 0:\n",
        "                    data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "                messageBuffer.clear()\n",
        "                date, time, author, message = getDatapoint(line)\n",
        "                messageBuffer.append(message)\n",
        "            else:\n",
        "                messageBuffer.append(line)\n",
        "                \n",
        "                \n",
        "    df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    #print(df.info())\n",
        "    \n",
        "    total_messages = df.shape[0]\n",
        "    print(\"total messages : \",total_messages)\n",
        "    \n",
        "    media_messages = df[df[\"Message\"]=='<Media omitted>'].shape[0]\n",
        "    print(\"media_messages: \", media_messages)\n",
        "    \n",
        "    def split_count(text):\n",
        "        emoji_list = []\n",
        "        data = regex.findall(r'\\X',text)\n",
        "        for word in data:\n",
        "            if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n",
        "                emoji_list.append(word)\n",
        "        return emoji_list\n",
        "    df['emoji'] = df[\"Message\"].apply(split_count)\n",
        "    emojis = sum(df['emoji'].str.len())\n",
        "    print(\"emojis: \", emojis)\n",
        "\n",
        "    URLPATTERN = r'(https?://\\S+)'\n",
        "    df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
        "    links = np.sum(df.urlcount)\n",
        "\n",
        "    print(\"Jeevika Group chat\")\n",
        "    print(\"Total Messages: \", total_messages)\n",
        "    print(\"Number of Media Shared: \", media_messages)\n",
        "    print(\"Number of Emojis Shared\", emojis)\n",
        "    print(\"Number of Links Shared\", links)\n",
        "    \n",
        "    media_messages_df = df[df['Message'] == '<Media omitted>']\n",
        "    messages_df = df.drop(media_messages_df.index)\n",
        "    messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
        "    messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
        "    messages_df[\"MessageCount\"]=1\n",
        "    \n",
        "    \n",
        "    #button_Select_Authors = Button(window,text = \"Click here to select Authors\", command = checkbox([messages_df['Author'].unique()]))\n",
        "\n",
        "    #l = ['Munger Fellow Sonam Bharati', 'i-Saksham Dharm Veer', 'Shravan Jha','Jam Bablu Jio', 'Aditya']\n",
        "    \n",
        "    if len(list_users) == 0:\n",
        "        l = list(messages_df['Author'].unique())\n",
        "    else:\n",
        "        l = list_users\n",
        "\n",
        "\n",
        "    messages_df = messages_df.loc[messages_df['Author'].isin(l)]\n",
        "\n",
        "    Author_data = []\n",
        "    for i in range(len(l)):\n",
        "      # Filtering out messages of particular user\n",
        "        req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
        "      # req_df will contain messages of only one particular user\n",
        "        #print(f'Stats of {l[i]} -')\n",
        "        Author_data.append(f'Stats of {l[i]} -')\n",
        "      # shape will print number of rows which indirectly means the number of messages\n",
        "        #print('Messages Sent', req_df.shape[0])\n",
        "        Author_data.append('Messages Sent '+ str(req_df.shape[0]))\n",
        "      #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
        "        words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
        "        #print('Average Words per message', words_per_message.round(2))\n",
        "        Author_data.append('Average Words per message ' + str(words_per_message.round(2)))\n",
        "      #media conists of media messages\n",
        "        media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
        "        #print('Media Messages Sent', media)\n",
        "        Author_data.append('Media Messages Sent '+str(media))\n",
        "      # emojis conists of total emojis\n",
        "        emojis = sum(req_df['emoji'].str.len())\n",
        "        #print('Emojis Sent', str(emojis))\n",
        "        Author_data.append('Emojis Sent '+str(emojis))\n",
        "      #links consist of total links\n",
        "        links = sum(req_df[\"urlcount\"])   \n",
        "        #print('Links Sent', str(links))\n",
        "        Author_data.append('Links Sent '+ str(links))\n",
        "\n",
        "    f=open(path+'\\Authors.txt','w')\n",
        "    Author_data=map(lambda x:x+'\\n', Author_data)\n",
        "    f.writelines(Author_data)\n",
        "    f.close()\n",
        "    \n",
        "    \n",
        "    total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))\n",
        "    total_emojis = len(total_emojis_list)\n",
        "\n",
        "    total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
        "    emoji_dict = dict(Counter(total_emojis_list))\n",
        "    emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    for i in emoji_dict:\n",
        "        #print(i)\n",
        "        emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "    import plotly.express as px\n",
        "    fig = px.pie(emoji_df.head(10), values='count', names='emoji', title = \"Top Ten Emojis\")\n",
        "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "    #fig.show()\n",
        "\n",
        "    fig.write_image(path+\"\\Top ten emojis.png\")\n",
        "    \n",
        "   # sg.Image(source = path+\"\\Top ten emojis.png\",size = (500,500))\n",
        "    \n",
        "    df = pd.read_csv('stp.csv')\n",
        "    \n",
        "    stop_word_hindi = []\n",
        "\n",
        "    for i in df['stp']:\n",
        "        stop_word_hindi.append(i)\n",
        "    stop_word_hindi = set(stop_word_hindi)\n",
        "    stopwords = set(STOP_WORDS_HI).union(stop_word_hindi)\n",
        "\n",
        "    stopwords = stopwords.union(STOPWORDS)\n",
        "    \n",
        "    messages_df['weekday'] = messages_df['Date'].apply(lambda x: x.day_name())\n",
        "    # new column month_sent\n",
        "    messages_df['month_sent'] = messages_df['Date'].apply(lambda x: x.month_name()) \n",
        "    #messages_df['hour'] = [d.hour for d in messages_df['Time']]\n",
        "    \n",
        "    hour = []\n",
        "    for i in messages_df['Time']:\n",
        "        if i.split(\" \")[2] == \"am\":\n",
        "            hour.append(int((i.split(\" \")[1]).split(\":\")[0]))\n",
        "        else:\n",
        "            hour.append(int((i.split(\" \")[1]).split(\":\")[0])+ 12)\n",
        "\n",
        "    messages_df['hour'] = [i for i in hour]\n",
        "    \n",
        "    date_grouped = messages_df.groupby('Date')['Message'].count().plot(kind='line', figsize=(20,10), color='#A26360',title = \"Message distribution per day\")\n",
        "    plt.savefig(path+\"\\messages per day.png\")\n",
        "    \n",
        "    weekday_grouped_msg =  (messages_df.set_index('weekday')['Message']\n",
        "                          .groupby(level=0)\n",
        "                          .value_counts()\n",
        "                          .groupby(level=0)\n",
        "                          .sum()\n",
        "                          .reset_index(name='count'))\n",
        "    weekday_grouped_msg\n",
        "\n",
        "    fig = px.line_polar(weekday_grouped_msg, r='count', theta='weekday', line_close=True)\n",
        "    fig.update_traces(fill='toself')\n",
        "    fig.update_layout(\n",
        "      polar=dict(\n",
        "        radialaxis=dict(\n",
        "          visible=True,\n",
        "        )),\n",
        "      showlegend=False\n",
        "    )\n",
        "    #fig.show()\n",
        "\n",
        "    fig.write_image(path+'\\weekday group message web chart.png')\n",
        "    \n",
        "    hour_grouped_msg =  (messages_df.set_index('hour')['Message']\n",
        "                          .groupby(level=0)\n",
        "                          .value_counts()\n",
        "                          .groupby(level=0)\n",
        "                          .sum()\n",
        "                          .reset_index(name='count'))\n",
        "    fig = px.bar(hour_grouped_msg, x='hour', y='count',\n",
        "                     labels={'hour':'24 Hour Period'}, \n",
        "                     height=400)\n",
        "    fig.update_traces(marker_color='#EDCC8B', marker_line_color='#D4A29C',\n",
        "                      marker_line_width=1.5, opacity=0.6)\n",
        "    fig.update_layout(title_text='Total Messages by Hour of the Day')\n",
        "    #fig.show()\n",
        "\n",
        "    fig.write_image(path+\"\\Total Messages by Hour of the day.png\")\n",
        "    \n",
        "    grouped_by_month_and_day = messages_df.groupby(['month_sent', 'weekday'])['Message'].value_counts().reset_index(name='count')\n",
        "    grouped_by_month_and_day\n",
        "    months= ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    pt = grouped_by_month_and_day.pivot_table(index= 'month_sent', columns= 'weekday', values='count').reindex(index=months, columns= days)\n",
        "    fig = px.imshow(pt,\n",
        "                    labels=dict(x=\"Day of Week\", y=\"Months\", color=\"Count\"),\n",
        "                    x=days,\n",
        "                    y=months\n",
        "                   )\n",
        "    fig.update_layout(\n",
        "        width = 700, height = 700)\n",
        "    #fig.show()\n",
        "\n",
        "    fig.write_image(path+\"\\Grouped by moth and day heatmap.png\")\n",
        "    \n",
        "    #qty_message_author = messages_df['Author'].value_counts().head(10)\n",
        "    #qty_message_author.plot(kind='barh',figsize=(20,10), color=['#D4A29C', '#E8B298', '#EDCC8B', '#BDD1C5', '#9DAAA2'])\n",
        "    \n",
        "    commond_words = messages_df[['Author','Message']].copy()\n",
        "\n",
        "\n",
        "    stopwords = list(stopwords)\n",
        "    extra = [\"https://\"]\n",
        "    stopwords = stopwords + extra\n",
        "    commond_words[\"Message\"] = (commond_words[\"Message\"]\n",
        "                               .str.lower()\n",
        "                               .str.split()\n",
        "                               .apply(lambda x: [item for item in x if item not in stopwords])\n",
        "                               .explode()\n",
        "                               .reset_index(drop=True)\n",
        "                     )\n",
        "\n",
        "    #commond_words['Message']= commond_words['Message'].apply(remove_emoji)\n",
        "    commond_words['Message']= commond_words['Message'].replace('nan', np.NaN)\n",
        "    commond_words['Message']= commond_words['Message'].replace('', np.NaN)\n",
        "    commond_words['Message']= commond_words.Message.str.replace(r\"(a|j)?(ja)+(a|j)?\", \"jaja\")\n",
        "    commond_words['Message']= commond_words.Message.str.replace(r\"(a|j)?(jaja)+(a|j)?\", \"jaja\")\n",
        "\n",
        "\n",
        "    words_dict = dict(Counter(commond_words.Message))\n",
        "    words_dict = sorted(words_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    words_dict = pd.DataFrame(words_dict, columns=['words', 'count'])\n",
        "\n",
        "    fig = px.bar(words_dict.head(10).dropna(), x='words', y='count',\n",
        "                     labels={'words':'Common Words'}, \n",
        "                     height=400)\n",
        "    fig.update_traces(marker_color='#EDCC8B', marker_line_color='#D4A29C',\n",
        "                      marker_line_width=1.5, opacity=0.6)\n",
        "    fig.update_layout(title_text='Commond Words Chart')\n",
        "    #fig.show()\n",
        "\n",
        "\n",
        "    fig.write_image(path+\"\\Common words by all.png\")\n",
        "    \n",
        "    TopTen =5\n",
        "    author_commond_words =  (commond_words.set_index('Author')['Message']\n",
        "                              .dropna()\n",
        "                              .groupby(level=0)\n",
        "                              .value_counts()\n",
        "                              .groupby(level=0)\n",
        "                              .head(TopTen)\n",
        "                              .rename_axis(('Author','words'))\n",
        "                              .reset_index(name='count'))\n",
        "\n",
        "    l = author_commond_words.Author.unique()\n",
        "    for i in range(len(l)):\n",
        "        dummy_df = author_commond_words[author_commond_words['Author'] == l[i]]\n",
        "        #print(dummy_df)\n",
        "        #print('Most Commond Words by', l[i])\n",
        "        fig = px.bar(dummy_df, x='words', y='count',\n",
        "                     labels={'words':l[i] + ' Common Words'}, \n",
        "                     height=380)\n",
        "        fig.update_traces(marker_color='#EDCC8B', marker_line_color='#D4A29C',\n",
        "                      marker_line_width=1.5, opacity=0.6)\n",
        "        fig.update_layout(title_text=l[i] + ' Commond Words Chart')\n",
        "        #fig.show()\n",
        "\n",
        "        fig.write_image(path+\"\\Common words by\"+l[i]+\".png\")\n",
        "        \n",
        "        #function to display wordcloud\n",
        "\n",
        "    #function to remove urls from text\n",
        "    def remove_urls(text):\n",
        "        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "        return url_pattern.sub(r'', text)\n",
        "    \n",
        "    font='Lohit-Devanagari.ttf'\n",
        "  \n",
        "    for i in l:\n",
        "        dummy = messages_df[messages_df.Author == i]\n",
        "        chat_word_cloud = dummy[['Message']].copy()\n",
        "        chat_word_cloud['Message']= chat_word_cloud['Message'].apply(remove_urls)\n",
        "        chat_word_cloud['Message']= chat_word_cloud['Message'].replace('nan', np.NaN)\n",
        "        chat_word_cloud['Message']= chat_word_cloud['Message'].replace('', np.NaN)\n",
        "        chat_word_cloud['Message']= chat_word_cloud.Message.str.replace(r\"(a|j)?(ja)+(a|j)?\", \"jaja\")\n",
        "        chat_word_cloud['Message']= chat_word_cloud.Message.str.replace(r\"(a|j)?(jaja)+(a|j)?\", \"jaja\")\n",
        "        text = \"\".join(review for review in chat_word_cloud.Message.dropna())\n",
        "\n",
        "        wordcloud = WordCloud(\n",
        "            width=3000,\n",
        "            height=2000,\n",
        "            random_state = 1,\n",
        "            background_color=\"white\", \n",
        "            colormap = 'Set1',\n",
        "            collocations = False,\n",
        "            stopwords=stopwords,\n",
        "            regexp=r\"[\\u0900-\\u097F]+\", \n",
        "            font_path=font\n",
        "            ).generate(text)\n",
        "            # Set figure size\n",
        "        #plt.figure(figsize=(40, 30))\n",
        "        # Display image\n",
        "        #plt.imshow(wordcloud) \n",
        "        # No axis details\n",
        "        #plt.axis(\"off\");\n",
        "        #plt.title(i);\n",
        "\n",
        "        wordcloud.to_file(path+'\\wordcloud for' + i + '.png')\n",
        "\n",
        "\n",
        "# In[92]:\n",
        "\n",
        "\n",
        "def get_Authors(filepath):\n",
        "    def date_time(s):\n",
        "        pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "        result = regex.match(pattern, s)\n",
        "        if result:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def find_author(s):\n",
        "        s = s.split(\":\")\n",
        "        if len(s)==2:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "            \n",
        "    def getDatapoint(line):\n",
        "        splitline = line.split(' - ')\n",
        "        dateTime = splitline[0]\n",
        "        date, time = dateTime.split(\",\")\n",
        "        message = \" \".join(splitline[1:])\n",
        "        if find_author(message):\n",
        "            splitmessage = message.split(\": \")\n",
        "            author = splitmessage[0]\n",
        "            message = \" \".join(splitmessage[1:])\n",
        "        else:\n",
        "            author= None\n",
        "        return date, time, author, message\n",
        "\n",
        "    data = []\n",
        "        #conversation = 'WhatsApp Chat with Jeevika-i-Saksham fellows.txt'\n",
        "    conversation = filepath\n",
        "    with open(conversation, encoding=\"utf-8\") as fp:\n",
        "        fp.readline()\n",
        "        messageBuffer = []\n",
        "        date, time, author = None, None, None\n",
        "        while True:\n",
        "            line = fp.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            line = line.strip()\n",
        "            if date_time(line):\n",
        "                if len(messageBuffer) > 0:\n",
        "                    data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "                    messageBuffer.clear()\n",
        "                    date, time, author, message = getDatapoint(line)\n",
        "                    messageBuffer.append(message)\n",
        "            else:\n",
        "                messageBuffer.append(line)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "        \n",
        "    return(list(df['Author'].unique()))\n",
        "\n",
        "par = [1,2,3]\n",
        "\n",
        "def file_browser():\n",
        "    sg.theme(\"DarkTeal2\")\n",
        "    layout = [[sg.T(\"\")], [sg.Text(\"Choose a file: \"), sg.Input(), sg.FileBrowse(key=\"-IN-\")],[sg.Button(\"Submit\")]]\n",
        "\n",
        "    ###Building Window\n",
        "    window = sg.Window('My File Browser', layout, size=(600,150))\n",
        "\n",
        "    while True:\n",
        "        event, values = window.read()\n",
        "        if event == sg.WIN_CLOSED or event==\"Exit\":\n",
        "            break\n",
        "        elif event == \"Submit\":\n",
        "            par[0] = values[\"-IN-\"]\n",
        "            window.close()\n",
        "\n",
        "def folder_browser():\n",
        "    sg.theme(\"DarkTeal2\")\n",
        "    layout = [[sg.T(\"\")], [sg.Text(\"Choose a folder: \"), sg.Input(key=\"-IN2-\" ,change_submits=True), sg.FolderBrowse(key=\"-IN-\")],[sg.Button(\"Submit\")]]\n",
        "\n",
        "    ###Building Window\n",
        "    window = sg.Window('My File Browser', layout, size=(600,150))\n",
        "\n",
        "    while True:\n",
        "        event, values = window.read()\n",
        "        if event == sg.WIN_CLOSED or event==\"Exit\":\n",
        "            break\n",
        "        elif event == \"Submit\":\n",
        "            par[1] = values[\"-IN-\"]\n",
        "            window.close()\n",
        "\n",
        "\n",
        "# In[93]:\n",
        "\n",
        "\n",
        "def checkbox():\n",
        "    sg.SetOptions(element_padding=(0,1))\n",
        "\n",
        "    lines = []\n",
        "    \n",
        "    n = len(get_Authors(par[0]))\n",
        "\n",
        "    for x in get_Authors(par[0]):\n",
        "        cb = sg.CB(text = x, key = x)\n",
        "        lines.append([cb])\n",
        "    \n",
        "    #layout = [[sg.T('Author Lists', font='Any 15')],\n",
        "              #*lines]\n",
        "\n",
        "    layout = [[sg.T('Author Lists', font='Any 15')],\n",
        "              [sg.Column(lines,size = (300,300),scrollable = True)]]\n",
        "    form = sg.Window(\"USERS\", layout, size = (300,300),resizable = True,)\n",
        "\n",
        "    button, values = form.read()\n",
        "\n",
        "    lst = []\n",
        "    for val in values:\n",
        "        if form.find_element(val).get()==True:\n",
        "            lst.append(val)\n",
        "    par[2] = lst\n",
        "\n",
        "\n",
        "# In[94]:\n",
        "\n",
        "\n",
        "file_browser()\n",
        "folder_browser()\n",
        "checkbox()\n",
        "do(par[0],par[1],par[2])\n",
        "\n",
        "sg.popup(\"Analytics Done!!\", \"Check Selected Folder For Analysis\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54b3f14142e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Zjw-H5OxJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}